{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f77ff58",
   "metadata": {},
   "source": [
    "# 03_text_processing_and_split.ipynb – Textverarbeitung & Datensatz-Splitting\n",
    "\n",
    "**Ziel:** Die preprocessed Amazon Reviews werden mit spaCy tokenisiert, von Stopwords bereinigt, lemmatisiert und anschließend stratifiziert in Trainings-, Validierungs- und Test­datensätze (80/10/10) aufgeteilt. Die Splits werden als .jsonl-Dateien im Ordner `data/processed/` gespeichert.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e6197",
   "metadata": {},
   "source": [
    "## 1. Setup und Laden der preprocessed Daten\n",
    "Wir laden die bereinigten Datensätze aus `data/preprocessed`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c30d99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automotive: 996426 Einträge geladen.\n",
      "Video_Games: 995507 Einträge geladen.\n",
      "Books: 997498 Einträge geladen.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PRE_DIR = Path('../data/preprocessed')\n",
    "CATEGORIES = ['Automotive', 'Video_Games', 'Books']\n",
    "dfs = {}\n",
    "for cat in CATEGORIES:\n",
    "    path = PRE_DIR / f'{cat}_preprocessed.jsonl'\n",
    "    df = pd.read_json(path, lines=True)\n",
    "    dfs[cat] = df\n",
    "    print(f'{cat}: {df.shape[0]} Einträge geladen.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59531d66",
   "metadata": {},
   "source": [
    "## 2. Tokenisierung, Stopword-Entfernung & Lemmatisierung mit spaCy\n",
    "Wir nutzen spaCy, um die Texte zu verarbeiten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8571e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearbeite Automotive ...\n",
      "Automotive: Verarbeitung abgeschlossen.\n",
      "Bearbeite Video_Games ...\n",
      "Video_Games: Verarbeitung abgeschlossen.\n",
      "Bearbeite Books ...\n",
      "Books: Verarbeitung abgeschlossen.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "\n",
    "def spacy_preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "for cat, df in dfs.items():\n",
    "    print(f'Bearbeite {cat} ...')\n",
    "    df['text_processed'] = df['text'].apply(spacy_preprocess)\n",
    "    dfs[cat] = df\n",
    "    print(f'{cat}: Verarbeitung abgeschlossen.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872bd22",
   "metadata": {},
   "source": [
    "## 3. Stratifiziertes Splitten in Train/Valid/Test\n",
    "Wir teilen die Daten im Verhältnis 80/10/10 auf und achten auf die Verteilung der Ratings. Die Splits werden im Ordner `data/processed/` gespeichert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e042ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automotive: Splits gespeichert unter ..\\data\\processed\n",
      "Video_Games: Splits gespeichert unter ..\\data\\processed\n",
      "Books: Splits gespeichert unter ..\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SPLIT_DIR = Path('../data/processed')\n",
    "SPLIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for cat, df in dfs.items():\n",
    "    # 80 % Train, 20 % Temp\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df, test_size=0.2, stratify=df['rating'], random_state=42\n",
    "    )\n",
    "    # Temp halbieren → 10 % Valid, 10 % Test\n",
    "    valid_df, test_df = train_test_split(\n",
    "        temp_df, test_size=0.5, stratify=temp_df['rating'], random_state=42\n",
    "    )\n",
    "    # Speichern\n",
    "    train_df.to_json(SPLIT_DIR / f'{cat}_train.jsonl', orient='records',\n",
    "                     lines=True, force_ascii=False)\n",
    "    valid_df.to_json(SPLIT_DIR / f'{cat}_valid.jsonl', orient='records',\n",
    "                     lines=True, force_ascii=False)\n",
    "    test_df.to_json(SPLIT_DIR / f'{cat}_test.jsonl', orient='records',\n",
    "                    lines=True, force_ascii=False)\n",
    "    print(f'{cat}: Splits gespeichert unter {SPLIT_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fd022",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
